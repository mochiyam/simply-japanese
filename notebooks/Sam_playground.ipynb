{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d0d4a-eb59-412e-badf-dff1a1b74c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install mecab-python3\n",
    "#These wheels include a copy of the MeCab library, but not a dictionary. \n",
    "#In order to use MeCab you'll need to install a dictionary. unidic-lite is a good one to start with:\n",
    "# !pip install unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ba96a-a4ac-4a45-9a0f-48de5898e38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalization tool\n",
    "# !pip install neologdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abbff6-adb4-474e-b92a-6d59c744aa8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ad56a-eede-439b-9581-0b940dff1ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # To be able to see Japanese!\n",
    "# !pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be0b4b-4e1e-42db-935b-100e95db2407",
   "metadata": {
    "tags": []
   },
   "source": [
    "everything was deleted what a christmas miracle....\n",
    "lets start again ...\n",
    "\n",
    "\n",
    "## Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba8a53d-8b81-449d-83da-d9d94f726dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "import MeCab\n",
    "import neologdn\n",
    "import collections\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "#import seaborn as sns # REMINDER: make sure to remove if not using!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc8467-21cf-4d4b-abf7-07fb4be1df4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = 'Combined_85K_150.xlsx'\n",
    "df = pd.read_excel(r'/home/samuelhenderson/code/simply-japanese/data/2_RawData/' + file_name)\n",
    "df.drop(columns=['#英語(原文)'], inplace=True)\n",
    "df.rename(columns={\"#日本語(原文)\": \"original\", \"#やさしい日本語\": \"simplified\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54cfef5-d120-4fca-81fd-49486d035817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cosine similarity \n",
    "# X= df['original']\n",
    "# y= df['simplified']\n",
    "\n",
    "# cosine_similarity(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99331bc-d05b-4cce-ae4a-450771e18aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#testing out stuff from github repository : \n",
    "# https://github.com/ZHAOTING/Japanese-sentence-similarity-scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c206c-99d3-4d6e-aba1-c4a4b9cdcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m unidic download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dd08b-ea4f-43b8-9974-4811e95b3061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #fast text\n",
    "# import fasttext\n",
    "# import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253da11-b0fa-4cd5-8606-8bd17d9ca319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext.util.download_model('jp', if_exists='ignore')  # English\n",
    "# ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3640525-e8e0-48d7-a40c-f26d2fb1b221",
   "metadata": {},
   "source": [
    "## SumEval & Bleu caluculator (Sacrebleu)\n",
    "-------------------------- can come back to this but WER sounds more promising... --------------------------\n",
    "\n",
    "https://github.com/chakki-works/sumeval#welcome-contribution-tada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a8ac1-6eb7-4e1c-9af5-26d103f3bd53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e031400-476d-487e-8767-8c96d8232cc5",
   "metadata": {},
   "source": [
    "Trying to get the right dependency for the sumeval & Bleu caluculator (Sacrebleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392c72d-0fce-4c7a-8045-9d40d1a6f2b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # pip install sumeval==0.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcfda2-645b-43d6-8f58-1535ed0ae7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip uninstall sumeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de4c4b-4954-4bb9-abdb-c2fef23976b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install janome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190ab8c-a2c5-4e05-8658-2e029aaca2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea230c-87f0-4d3e-85cb-b33acd30775a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sacrebleu import corpus_bleu, DEFAULT_TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc3c6b-c7b4-4c6a-a566-aefe500905aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(df.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b694d-4296-4e21-8127-bb10b9e767e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sumeval.metrics.bleu import BLEUCalculator\n",
    "# # https://github.com/chakki-works/sumeval\n",
    "# from janome.tokenizer import Tokenizer\n",
    "\n",
    "# # bleu calculator for english\n",
    "# # bleu = BLEUCalculator()\n",
    "# # score = bleu.bleu(\"I am waiting on the beach\",\n",
    "# #                   \"He is walking on the beach\")\n",
    "\n",
    "# # bleu calculator for Japanese\n",
    "# bleu_ja = BLEUCalculator(lang=\"ja\")\n",
    "# score_ja = bleu_ja.bleu(df.iloc[0][0], df.iloc[0][1])\n",
    "# tokenizer_ja()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329473b-35b7-403e-b8cb-4d493969fa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sumeval.metrics.bleu import BLEUCalculator\n",
    "\n",
    "# bleu = BLEUCalculator()\n",
    "# score = bleu.bleu(\"I am waiting on the beach\",\n",
    "#                   \"He is walking on the beach\")\n",
    "\n",
    "# # bleu_ja = BLEUCalculator(lang=\"ja\")\n",
    "# # score_ja = bleu_ja.bleu(\"私はビーチで待ってる\", \"彼がベンチで待ってる\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6095541-ba51-4936-82b0-e405b62a9f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sacrebleu import ja_mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e3ca2-8166-4352-9708-2a654c3eab47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bleu = BLEUCalculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25114726-fd99-4add-ba04-1bc24041cab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3aec6c-1e5c-496e-b889-7540da0e0075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "# bleu_ja = BLEUCalculator(lang=\"ja\")\n",
    "# score_ja = bleu_ja.bleu(df.iloc[0][0], df.iloc[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae464aa-626e-47fb-bfef-9d961e674c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110f30e-94d8-4007-b6fc-011e8066d670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacrebleu.info()\n",
    "# https://github.com/chakki-works/sumeval#welcome-contribution-tada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24b895-bcd9-4771-9e39-72e2e33fc172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "# refs = [ # First set of references\n",
    "#           ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.'],\n",
    "#           # Second set of references\n",
    "#           ['The dog had bit the man.', 'No one was surprised.', 'The man had bitten the dog.'],\n",
    "#         ]\n",
    "# sys = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "# bleu = BLEU()\n",
    "\n",
    "# bleu.corpus_score(sys, refs)\n",
    "# # BLEU = 48.53 82.4/50.0/45.5/37.5 (BP = 0.943 ratio = 0.944 hyp_len = 17 ref_len = 18)\n",
    "\n",
    "# bleu.get_signature()\n",
    "# # nrefs:2|case:mixed|eff:no|tok:13a|smooth:exp|version:2.0.0\n",
    "\n",
    "# chrf = CHRF()\n",
    "\n",
    "# chrf.corpus_score(sys, refs)\n",
    "# # chrF2 = 59.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fea000-cb5e-492b-98a5-69f44b0bf64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77574ae3-26c3-477b-b69e-4848ddc3cecf",
   "metadata": {},
   "source": [
    "## WER (Word Error Rate) and Edit Distance\n",
    "WER - https://en.m.wikipedia.org/wiki/Word_error_rate \n",
    "WER= {S+D+I}/{N}={S+D+I}/{S+D+C}\n",
    "where:\n",
    "\n",
    "**S** is the number of substitutions,\n",
    "\n",
    "**D** is the number of deletions,\n",
    "\n",
    "**I** is the number of insertions,\n",
    "\n",
    "**C** is the number of correct words,\n",
    "\n",
    "**N** is the number of words in the reference (N=S+D+C)\n",
    "\n",
    "Edit Distance (Levenshtein distance) https://en.m.wikipedia.org/wiki/Edit_distance\n",
    "Takes two either been an insert/remove/replace of characters.\n",
    "\n",
    "i.e. \n",
    "Input:   str1 = “geek”, str2 = “gesek”\n",
    "\n",
    "Output:  1\n",
    "\n",
    "Explanation: We can convert str1 into str2 by inserting a ‘s’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79f5a6-f152-4273-a616-6a264ba6ea0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515953e-e2d6-4863-8787-2954a1a78144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A WER function I found online.\n",
    "# Seems be going off legth of characters in simplification process,\n",
    "# But in a fair few of the conversions the phrases get longer.\n",
    "\n",
    "def wer(ref, hyp ,debug=True):\n",
    "    r = ref.split()\n",
    "    h = hyp.split()\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    # backtrace will hold the operations we've done.\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    # First column represents the case where we achieve zero\n",
    "    # hypothesis words by deleting all reference words.\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    \n",
    "    # First row represents the case where we achieve the hypothesis\n",
    "    # by inserting all hypothesis words into a zero-length reference.\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    \n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        # print(\"OP\\tREF\\tHYP\")\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    # if debug:\n",
    "    #     lines = reversed(lines)\n",
    "    #     for line in lines:\n",
    "    #         print(line)\n",
    "            \n",
    "        # Removing all the extra bits we dont need at this second\n",
    "\n",
    "        # print(\"#correct words \" + str(numCor))\n",
    "        # print(\"#substitutions \" + str(numSub))\n",
    "        # print(\"#deleltions \" + str(numDel))\n",
    "        # print(\"#insertions \" + str(numIns))\n",
    "    return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    \n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    print({'WER':wer_result, 'numCorrect':numCor, 'numSubstitutions':numSub, 'numInserts':numIns, 'numDelete':numDel, \"numCount\": len(r)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c84366-d2b6-4560-a531-17729aa88c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing first sample\n",
    "wer(df.iloc[0][0], df.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06ee29-42c1-4143-86a1-3e2d02462c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc329c-3495-4bf3-80ab-19aa5cbb8fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing Sample 2\n",
    "wer(df.iloc[2][0], df.iloc[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ee65b-ef56-4065-9b31-d3d9c96cc754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking if the length of the characters are of different lengths for the 2nd Sample.\n",
    "len(df.iloc[2][0]), len(df.iloc[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50291e0-bfa8-4e18-b7bd-0d40d10dbeec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Finding the samples with differences in characters...\")\n",
    "for i in range(150):\n",
    "    if len(df.iloc[i][0])> len(df.iloc[i][1]):\n",
    "        print(i, len(df.iloc[i][0]), len(df.iloc[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad58c4b-f32f-454e-a565-f6b36c1fe9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing on the original to simplified sentences with the WER metric\n",
    "# returing sentence as whole string so not able to give us much insight\n",
    "# Only returning if it is a WER of 0 if it is the same,\n",
    "# Or returning a WER of 1.0 if it is differnt\n",
    "\n",
    "# \n",
    "print('Testing WER on simplified sentences with smaller outputs than input...')\n",
    "print('')\n",
    "for i in range(150):    \n",
    "    if len(df.iloc[i][0])> len(df.iloc[i][1]):\n",
    "        print('Sample', i+1)\n",
    "        print('Difference in Characters = ', len(df.iloc[i][0]) - len(df.iloc[i][1]))\n",
    "        print(len(df.iloc[i][0]) - len(df.iloc[i][1]))\n",
    "        wer(df.iloc[i][0], df.iloc[i][1])\n",
    "        print('*******************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db71cf6-2cf6-4be2-8265-d6bf86dc640f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just checking on a string in Enlgish how it works...\n",
    "# i = 10\n",
    "wer('I love to dance and sing', 'I love singing and i love to do dancing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905171ea-2c21-47d3-a675-fa9a02145ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d21f33-1b85-4072-a760-1b73bb1a7d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Making a function to iterate over the whole Data set to to see what it spits out\n",
    "\n",
    "#Creating a Function to split all characters to determine how many have been changed.\n",
    "def wer_jp(original, simplified):       \n",
    "    ori = ''\n",
    "    simpi = ''\n",
    "    wer_score = []\n",
    "    for i in original:\n",
    "        ori += i + ' '\n",
    "    for i in simplified:\n",
    "        simpi += i + ' '\n",
    "    # if round(wer(ori, simpi),3):\n",
    "    print('WER Score ', round(wer(ori, simpi),3))\n",
    "        # df.insert(2, \"WER Score\", round(wer(ori, simpi), True))\n",
    "    return round(wer(ori, simpi),3)\n",
    "    return wer_score   \n",
    "\n",
    "# for i in df.index:\n",
    "#     original_text = df.iloc[i][0] \n",
    "#     simplified_text = df.iloc[i][1]\n",
    "#     print('******************')\n",
    "#     print('Testing sample ', i+1)\n",
    "#     # print('******************')\n",
    "#     wer_jp(original_text, simplified_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cce5e-e2fd-4b18-a28a-693385b7a70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['WER_score'] = wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5e6ae-5c2f-48ac-9dfe-17da875d2117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319abf77-6b77-48c3-8c92-c41222f110b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.histplot(df['WER_score'], bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb5c17-5dd6-4a4b-b315-4506f117071a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wer_score(predicted, simplified, debug=True):\n",
    "    '''\n",
    "    Compares the simplified ML prediction of a given text to the pre-existing simplified\n",
    "    text given with the dataframe.\n",
    "    Using the WER (word error rate) algorithm. \n",
    "    Adds the WER score as a new column to the Dataframe\n",
    "    '''\n",
    "    r = predicted.split()\n",
    "    h = simplified.split()\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    " \n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    \n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                 \n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "                 \n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    \n",
    "    if debug:\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    \n",
    "    return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "\n",
    "def wer_jp(original, simplified):       \n",
    "    ori = ''\n",
    "    simpi = ''\n",
    "    wer_score = []\n",
    "    for i in original:\n",
    "        ori += i + ' '\n",
    "    for i in simplified:\n",
    "        simpi += i + ' '\n",
    "    print('WER Score ', round(wer(ori, simpi),3))\n",
    "    return round(wer(ori, simpi),3)\n",
    "    return wer_score\n",
    "    \n",
    "def evaluate_wer_score(df):\n",
    "    wer_list = []\n",
    "    for i in df.index:\n",
    "        original_text = df.iloc[i][0] \n",
    "        simplified_text = df.iloc[i][1]\n",
    "        wer_list.append(wer_jp(original_text, simplified_text))\n",
    "    df['WER_score'] = wer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8073e-4b2c-4142-b48e-150b4b55bde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluating(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04513fd7-56b3-4953-8359-cc104a5e00cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e629f9bc-9185-4ef0-888b-fa5c5f51fb60",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tensorflow Seq2Seq\n",
    "Having a play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c407a00-7bfb-49ee-ae96-bc0608ab9113",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d8006-05d5-4952-8aa0-06ddbe3d2f51",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2a441-fb03-4242-bbc2-a00b90675b22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7e3d5-c95e-4e44-9518-468d9fdecf15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # remove diacritics (accents)\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    # remove punctuation and digits\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation + string.digits), '', text)\n",
    "    # remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def prepare_text_dataset(texts, max_vocab_size=10000, max_seq_len=100):\n",
    "    vectorizer = TextVectorization(max_tokens=max_vocab_size, output_mode='int', output_sequence_length=max_seq_len)\n",
    "    vectorizer.adapt(texts)\n",
    "    return vectorizer\n",
    "\n",
    "def prepare_seq2seq_dataset(texts, vectorizer):\n",
    "    input_texts = ['<start> ' + text for text in texts]\n",
    "    target_texts = [text + ' <end>' for text in texts]\n",
    "    input_seqs = vectorizer(np.array(input_texts))[:, :-1]\n",
    "    target_seqs = vectorizer(np.array(target_texts))[:, 1:]\n",
    "    return (input_seqs, target_seqs)\n",
    "\n",
    "\n",
    "#Preprocess text and prepare the datasetfor seq2seq transformer\n",
    "df['text'] = df['text'].apply(preprocess)\n",
    "max_vocab_size = 10000\n",
    "max_seq_len = 100\n",
    "text_vectorizer = prepare_text_dataset(df['text'], max_vocab_size, max_seq_len)\n",
    "input_seqs, target_seqs = prepare_seq2seq_dataset(df['text'], text_vectorizer)\n",
    "\n",
    "\n",
    "# Let's create the seq2seq transformer model:\n",
    "embedding_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1\n",
    "input_vocab_size = max_vocab_size + 2\n",
    "target_vocab_size = max_vocab_size + 2\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "targets = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "encoder = keras.layers.Encoder(input_vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "decoder = keras.layers.Decoder(target_vocab_size, embedding_dim, num_heads, ff_dim, dropout_rate)\n",
    "outputs = decoder(encoder(inputs), targets)\n",
    "\n",
    "model = keras.Model([inputs, targets], outputs)\n",
    "\n",
    "\n",
    "# Let's compile the model and train it on the dataset:\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit([input_seqs, target_seqs], target_seqs, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "def predict_simplified_text(model, text, vectorizer, max_len=100):\n",
    "    text = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734d768-fbf4-4ea8-b773-62adbe41f244",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  BLEU Score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Example reference and candidate sentences\n",
    "reference = ['私は犬が好きです', 'あなたは猫が好きですか']\n",
    "candidate = '私は猫が好きです'\n",
    "\n",
    "# Compute the BLEU score for the candidate sentence\n",
    "# score = sentence_bleu(reference, candidate)\n",
    "# print('BLEU score:', score)\n",
    "\n",
    "score = sentence_bleu(df.iloc[0][0], df.iloc[0][1])\n",
    "print('BLEU score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d846d821-3f73-425a-b749-906bc82717a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprossesssing\n",
    "import MeCab\n",
    "import sudachipy\n",
    "from pyknp import Juman\n",
    "import re\n",
    "import fasttext\n",
    "\n",
    "# Set up MeCab tokenizer\n",
    "mecab = MeCab.Tagger('-Owakati')\n",
    "\n",
    "# Set up SudachiPy tokenizer\n",
    "sudachi = sudachipy.Dictionary().create()\n",
    "\n",
    "# Set up Juman tokenizer\n",
    "juman = Juman()\n",
    "\n",
    "# Set up FastText model\n",
    "model = fasttext.load_model('cc.ja.300.bin')\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize the text using MeCab\n",
    "    tokens = mecab.parse(text).split()\n",
    "    \n",
    "    # Tokenize the text using SudachiPy\n",
    "    sudachi_tokens = sudachi.tokenize(text)\n",
    "    sudachi_tokens = [morph.surface() for morph in sudachi_tokens]\n",
    "    \n",
    "    # Tokenize the text using Juman\n",
    "    juman_tokens = juman.analysis(text)\n",
    "    juman_tokens = [mrph.midasi for mrph in juman_tokens.mrph_list()]\n",
    "    \n",
    "    # Combine the tokens from all tokenizers\n",
    "    tokens += sudachi_tokens\n",
    "    tokens += juman_tokens\n",
    "    tokens = list(set(tokens))  # Remove duplicates\n",
    "    \n",
    "    # Remove stop words and punctuation\n",
    "    stopwords = ['は', 'を', 'に', 'が', 'の', 'て', 'と', 'た', 'し', 'する', 'れる', 'さ', 'など']\n",
    "    tokens = [token for token in tokens if token not in stopwords and not re.match(r'[。、・！？（）「」『』【】〈〉“”’‘｜\\n]+', token)]\n",
    "\n",
    "    # Insert spaces between Kanji and Hiragana/Katakana\n",
    "    text = re.sub(r'(?<=[一-龯])(?=[ぁ-んァ-ン])', ' ', text)\n",
    "    \n",
    "    # Normalize the text\n",
    "    text = sudachi.normalize(text)\n",
    "    \n",
    "    # Encode the words using FastText embedding\n",
    "    vectors = [model.get_word_vector(word) for word in tokens]\n",
    "    \n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45276c95-37e0-4ac0-88b2-3cfb7d173584",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Look into this:\n",
    "https://huggingface.co/sonoisa/t5-base-japanese\n",
    "\n",
    "Moana is attmepting to use the same model too.. See what we can both come up with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79ffb6-924e-4a34-b9a3-879a949b991d",
   "metadata": {},
   "source": [
    "# Trying out this model ... lots of big imports to install taking a long time...\n",
    "\n",
    "https://tsmatz.wordpress.com/2022/11/25/huggingface-japanese-summarization/\n",
    "\n",
    "\n",
    "https://github.com/huggingface/transformers/blob/main/src/transformers/models/t5/modeling_t5.py\n",
    "\n",
    "https://github.com/huggingface/transformers/issues/4092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f28487-fad7-4ac0-9e75-eeadf4e24f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenize text into ids\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sonoisa/t5-base-japanese\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"sonoisa/t5-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0194b6eb-9c8a-42f1-a7a9-36aaa897dff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# sequence to id\n",
    "seq2seq = pipeline(\"summarization\", model=\"tsmatz/mt5-summarize-jp\")\n",
    "sample_text = \"サッカーのワールドカップカタール大会、世界ランキング24位でグループEに属する日本は、23日の1次リーグ初戦において、世界11位で過去4回の優勝を誇るドイツと対戦しました。試合は前半、ドイツの一方的なペースではじまりましたが、後半、日本の森保監督は攻撃的な選手を積極的に動員して流れを変えました。結局、日本は前半に1点を奪われましたが、途中出場の堂安律選手と浅野拓磨選手が後半にゴールを決め、2対1で逆転勝ちしました。ゲームの流れをつかんだ森保采配が功を奏しました。\"\n",
    "result = seq2seq(sample_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad74010-4fad-4097-9ee1-5d9191e69a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model and data collator\n",
    "import torch\n",
    "from transformers import AutoConfig, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# see https://huggingface.co/docs/transformers/main_classes/configuration\n",
    "mt5_config = AutoConfig.from_pretrained(\n",
    "  \"google/mt5-small\",\n",
    "  max_length=128,\n",
    "  length_penalty=0.6,\n",
    "  no_repeat_ngram_size=2,\n",
    "  num_beams=15,\n",
    ")\n",
    "model = (TFAutoModelForSeq2SeqLM\n",
    "         .from_pretrained(\"google/mt5-small\", config=mt5_config))\n",
    "         # .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2448e75-2495-4d63-859c-02887916e60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "t5_tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535fad2-e3fe-4cba-a4cd-61f70c35984b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # Max token size is 14536 and 215 for inputs and labels, respectively.\n",
    "  # Here I restrict these token size.\n",
    "  input_feature = t5_tokenizer(data[\"text\"], truncation=True, max_length=1024)\n",
    "  label = t5_tokenizer(data[\"summary\"], truncation=True, max_length=128)\n",
    "  return {\n",
    "    \"input_ids\": input_feature[\"input_ids\"],\n",
    "    \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "    \"labels\": label[\"input_ids\"],\n",
    "  }\n",
    "\n",
    "tokenized_df = df.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"url\", \"title\", \"summary\", \"text\"],\n",
    "  batched=True,\n",
    "  batch_size=128)\n",
    "\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324c381-e22c-4258-8325-018cdd1411c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "  t5_tokenizer,\n",
    "  model=model,\n",
    "  return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9fd60-216e-4853-a42b-5e78adca32d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# define function for custom tokenization\n",
    "def tokenize_sentence(arg):\n",
    "  encoded_arg = t5_tokenizer(arg)\n",
    "  return t5_tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "# define function to get ROUGE scores with custom tokenization\n",
    "def metrics_func(eval_arg):\n",
    "  preds, labels = eval_arg\n",
    "  # Replace -100\n",
    "  labels = np.where(labels != -100, labels, t5_tokenizer.pad_token_id)\n",
    "  # Convert id tokens to text\n",
    "  text_preds = t5_tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  text_labels = t5_tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
    "  # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
    "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
    "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
    "  sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
    "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
    "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
    "  # compute ROUGE score with custom tokenization\n",
    "  return rouge_metric.compute(\n",
    "    predictions=text_preds,\n",
    "    references=text_labels,\n",
    "    tokenizer=tokenize_sentence\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282c9dd-8fcd-4c35-964e-b7056afc24ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sample_dataloader = DataLoader(\n",
    "  tokenized_df[\"test\"].with_format(\"torch\"),\n",
    "  collate_fn=data_collator,\n",
    "  batch_size=5)\n",
    "for batch in sample_dataloader:\n",
    "  with torch.no_grad():\n",
    "    preds = model.generate(\n",
    "      batch[\"input_ids\"].to(device),\n",
    "      num_beams=15,\n",
    "      num_return_sequences=1,\n",
    "      no_repeat_ngram_size=1,\n",
    "      remove_invalid_values=True,\n",
    "      max_length=128,\n",
    "    )\n",
    "  labels = batch[\"labels\"]\n",
    "  break\n",
    "\n",
    "metrics_func([preds, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f437d3f-c6f8-4bbb-87c3-291c2349174b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir = \"mt5-summarize-ja\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 10,\n",
    "  learning_rate = 5e-4,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 90,\n",
    "  optim = \"adafactor\",\n",
    "  weight_decay = 0.01,\n",
    "  per_device_train_batch_size = 2,\n",
    "  per_device_eval_batch_size = 1,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 100,\n",
    "  predict_with_generate=True,\n",
    "  generation_max_length = 128,\n",
    "  save_steps = 500,\n",
    "  logging_steps = 10,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea0e81-a0c1-44b8-973d-b02833bb5c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer class that fine tunes the model\n",
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  data_collator = data_collator,\n",
    "  compute_metrics = metrics_func,\n",
    "  train_dataset = tokenized_ds[\"train\"],\n",
    "  eval_dataset = tokenized_ds[\"validation\"].select(range(20)),\n",
    "  tokenizer = t5_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
