{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04eecb0-8de6-4d5c-9e0a-de059928df2e",
   "metadata": {},
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327925a-fb15-457b-91b7-b9d283bcce2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Information on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5bf8aa-48f5-4c32-ab86-7cacc1cea3a9",
   "metadata": {},
   "source": [
    "Data Fields for SNOW T15 and SNOW T23 ⛄<br>\n",
    "Resource: https://huggingface.co/datasets/snow_simplified_japanese_corpus <br>\n",
    "Paper: https://aclanthology.org/L18-1072.pdf\n",
    "\n",
    "- <strong>ID</strong>: sentence ID.\n",
    "- <strong>original_ja</strong>: original Japanese sentebolnce.\n",
    "- <strong>simplified_ja</strong>: simplified Japanese sentence.\n",
    "- <strong>original_en</strong>: original English sentence.\n",
    "- <strong>proper_noun</strong>: (included ONLY in SNOW T23) Proper nowus that the workers has extracted as proper nouns. The authors instructed workers not to rewrite proper nouns, leaving the determination of proper nouns to the workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65e0c0-f8b3-4be5-8012-11c91ba07221",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef06295-331e-4e2e-84ee-538e9aead275",
   "metadata": {},
   "source": [
    "In the SNOW T15 dataset it states: <br>\n",
    "<i>Core vocabulary is restricted to 2,000 words where it is selected by accounting for several factors such as meaning preservation, variation, simplicity and the UniDic word segmentation criterion/</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae1fe8-1d47-48ab-ac7f-70e4c363431e",
   "metadata": {},
   "source": [
    "#### Step 1: Take a sample size from the SNOW T15 dataset and extracted 2,000 simplified terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd34b4-c125-445c-ace0-a1b1c130f513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" Required installations \"\"\"\n",
    "\n",
    "# !pip install mecab-python3\n",
    "# #These wheels include a copy of the MeCab library, but not a dictionary. \n",
    "# #In order to use MeCab you'll need to install a dictionary. unidic-lite is a good one to start with:\n",
    "# !pip install unidic-lite\n",
    "\n",
    "# # normalization tool\n",
    "# !pip install neologdn\n",
    "\n",
    "# !pip install openpyxl\n",
    "\n",
    "# # To be able to see in Japanese!\n",
    "# !pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51f78cb4-2298-4c4b-9bcb-cd7ea9ac4218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Preprocessing\n",
    "import MeCab\n",
    "import neologdn\n",
    "import collections\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import collections\n",
    "import logging\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a2576f-7fac-48bc-94cd-c8edfbb1a1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    \"\"\"\n",
    "    Gets csv data under 'simply-japanese/data/'\n",
    "    Returns as Dataframe where columns=['original','simplified']\n",
    "    \"\"\"\n",
    "\n",
    "    # FIXME:  Make sure to\n",
    "    # 1. Change these when you transfer to .py file\n",
    "    # 2. Put these global variables somewhere else\n",
    "    \n",
    "    CURRENT_PATH = 'notebooks/baseline_workflow.ipynb'\n",
    "    DATA_PATH = 'data/2_RawData'\n",
    "    csv_path = os.path.abspath(__file__)[:-len(CURRENT_PATH)]  + DATA_PATH\n",
    "    df = pd.read_excel(os.path.join(csv_path, file))\n",
    "    \n",
    "    df.drop(columns=['#英語(原文)','#固有名詞'], inplace=True, errors='ignore')\n",
    "    df.rename(columns={\"#日本語(原文)\": \"original\", \"#やさしい日本語\": \"simplified\"}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e798266-15fb-4aaa-a9fd-e348d22802d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIXME: Set df in __init__ \n",
    "def term_frequency(df, col='original'):\n",
    "    \"\"\"\n",
    "    Count number of terms in a corpus\n",
    "    Ignore independent words  [\"助動詞\", \"助詞\", \"補助記号\"] and words in japanese stopwords\n",
    "    Returns collection of term and its frequency\n",
    "    \"\"\"\n",
    "    # FIXME : Need to find a way to implement japanese_stopword.txt when this file is used externally\n",
    "    jp_stopwords = stopwords.words('japanese')\n",
    "    all_terms = collections.Counter()\n",
    "    t = MeCab.Tagger(\"-O wakati\")\n",
    "    for idx, row in df.iterrows():\n",
    "        text = row[col]\n",
    "        node = t.parseToNode(text).next\n",
    "        while node.next:\n",
    "            part_of_speech = node.feature.split(',')[0]\n",
    "            # TBD\n",
    "            if part_of_speech in [\"助動詞\", \"助詞\", \"補助記号\"] or node.surface in jp_stopwords:\n",
    "                node = node.next\n",
    "                continue\n",
    "            all_terms[node.surface] += 1\n",
    "            node = node.next\n",
    "    return all_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1317e0-a444-48ee-96a5-c6c5394cb5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_simplified_terms(df, n_most_common):\n",
    "    \"\"\"\n",
    "    Only returns simplified terms that exists in the simplified column\n",
    "    Return list until the top 'n' elements from most common\n",
    "    \"\"\"\n",
    "    # Filter out corpuses if original and simplified are exactly the same\n",
    "    diff_corpus_df = df[df['original'] != df['simplified']]\n",
    "    \n",
    "    # Create collections of original and simplified terms\n",
    "    original_terms = term_frequency(diff_corpus_df, 'original')\n",
    "    simplified_terms = term_frequency(diff_corpus_df, 'simplified')\n",
    "    \n",
    "    # Compare two collections using subtract\n",
    "    diff_terms = simplified_terms\n",
    "    diff_terms.subtract(original_terms)\n",
    "    \n",
    "    diff_terms_df = pd.DataFrame(dict(diff_terms).items(), columns=['word', 'count'])\n",
    "    return diff_terms_df[diff_terms_df['count'] >= 0].sort_values(by='count', ascending=False)['word'].tolist()[:n_most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc32146-ec4f-4b67-be21-7c13056de149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e885583-5695-47c7-b61b-a646f88542b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f57e2f-4d1f-4046-b262-2070dcfff634",
   "metadata": {},
   "source": [
    "#### Step 2: Using the 2000 list of simplified terms from Step 1, find the nearest term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1de6d-b5d1-4c51-ab1d-c8523a09271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf_list = 2000 simplified term frequency retrieved from data\n",
    "pos_list = specified list of POS (Parts-Of-Speech)\n",
    "\n",
    "1. Go through each row in the original data\n",
    "2. Check it word is in the pos_list\n",
    "3. Check if a word is in the tf_list\n",
    "    if yes, continue to the next word\n",
    "4. If 2. is no: check the similarity of the word with all the tf_list\n",
    "5. Replace the word with maximum value and if the maximium exceeds a specified threshold\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "PSEUDO CODE\n",
    "\n",
    "threshold = minimum similarity\n",
    "for sentence in data:\n",
    "    for word in sentence:\n",
    "        if word.pos in pos_list:\n",
    "            if word in tf_list:\n",
    "                continue\n",
    "            else:\n",
    "                for tf in tf_list:\n",
    "                    list = []\n",
    "                    list.append(wv.similarity(word, tf))\n",
    "                replace word with max(list) if max(list) > threshold\n",
    "        else: continue\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da21b6b-9cba-41b9-bd1a-02167726dd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30d9bc5e-3df2-4ea3-88e5-0be23adc59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version that can handle romaji, also changed the way it handles numerals\n",
    "\n",
    "def is_romaji(string):\n",
    "    \"\"\"\n",
    "    returns True if string contains Romaji or a number, False if not.\n",
    "    \"\"\"\n",
    "    alphanum_full = r'[A-z0-9]'\n",
    "    if re.findall(alphanum_full, string):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def replace_terms(data, term_list, wv):\n",
    "    \"\"\"\n",
    "    1. Identify every POS in a sentence and if it should be replaced\n",
    "    2. Use the pre-trained Word2Vec model to get a term from term_list with closest distance to POS\n",
    "    3. Replace POS in sentence\n",
    "    4. Add new sentence to dataframe in column \"prediction\"\n",
    "\n",
    "    input:\n",
    "    data, np.series\n",
    "    term_list, list of simplified terms\n",
    "    wv, word2vec model.wv\n",
    "\n",
    "    output:\n",
    "    prediction, np.series\n",
    "    \"\"\"\n",
    "    logging.root.setLevel(logging.INFO)\n",
    "\n",
    "    start = time.time()\n",
    "    # Make sure the data is a series, not a df or list\n",
    "    try:\n",
    "        assert type(data) == pd.core.series.Series\n",
    "        logging.info(\"Data file type OK\")\n",
    "    except:\n",
    "        print(\"Data file type is NOT a pd.series\")\n",
    "\n",
    "    pos_list = (\"名詞\", \"動詞\", \"代名詞\") # POS (part of speech) that will possibly be removed\n",
    "    threshold = 0.5 # Threshold of similarity, over which a term will be replaced\n",
    "    t = MeCab.Tagger()\n",
    "    counter = collections.Counter()\n",
    "    prediction = data.copy()\n",
    "    assert len(prediction) == len(data)     # Make sure prediction and data have the same size\n",
    "\n",
    "    # Iterate over every sentence in the dataset\n",
    "    for idx, row in data.items():\n",
    "        row = neologdn.normalize(row)\n",
    "        logging.debug(f\"Currrent sentence: {row}\")\n",
    "        sentence = []\n",
    "        # Iterate over every word in the sentence\n",
    "        node = t.parseToNode(row).next\n",
    "        while node.next:\n",
    "            if is_romaji(node.surface):\n",
    "                sentence.append(node.surface)\n",
    "                node = node.next\n",
    "            word = node.feature.split(',')[8]\n",
    "            part_of_speech = node.feature.split(',')[0]\n",
    "            # If POS is not noun, pronoun or verb: add word to list and continue\n",
    "            if part_of_speech not in pos_list:\n",
    "                sentence.append(word)\n",
    "            else:\n",
    "                # If the term is already in the term list: do not replace, add word to list and continue\n",
    "                if word in term_list:\n",
    "                    sentence.append(word)\n",
    "                else:\n",
    "                    # Replace word with closest word from term list\n",
    "                    try:\n",
    "                        if wv.most_similar(word)[0][1] > threshold:\n",
    "                            closest_word = wv.most_similar(word)[0][0]\n",
    "                            sentence.append(closest_word)\n",
    "                        else:\n",
    "                            sentence.append(word)\n",
    "                    except KeyError as e:\n",
    "                        sentence.append(word)\n",
    "                        logging.warning(f\"{e}. Term will not be replaced.\")\n",
    "            counter[node.surface] += 1\n",
    "            node = node.next\n",
    "        logging.debug(sentence)\n",
    "        prediction[idx] = \"\".join(sentence)\n",
    "\n",
    "    assert len(data) == len(prediction)  # Make sure prediction and data have the same size\n",
    "    end = time.time()\n",
    "    logging.info(end-start)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48332544-1522-436e-b226-6851ce288379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X150 = get_data('SNOW_T15_150.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a56dc0c1-fc37-458d-aacd-11bcaa29f49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>月曜日までにこの仕事を終えて下さい。</td>\n",
       "      <td>月曜日までにこの仕事を終わらせてください。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>失敗してもあきらめてはいけない。</td>\n",
       "      <td>失敗してもダメと思ってはならない。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>あなたは何を見つめているのですか。</td>\n",
       "      <td>あなたは何を見ているのですか。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>その女の子は母と似ていた。</td>\n",
       "      <td>その少女は母と似ていた。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>彼は貧しかったので、大学へ行けなかった。</td>\n",
       "      <td>彼はお金がなかったので、大学へ行くことができなかった。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               original                   simplified\n",
       "0    月曜日までにこの仕事を終えて下さい。        月曜日までにこの仕事を終わらせてください。\n",
       "1      失敗してもあきらめてはいけない。            失敗してもダメと思ってはならない。\n",
       "2     あなたは何を見つめているのですか。              あなたは何を見ているのですか。\n",
       "3         その女の子は母と似ていた。                 その少女は母と似ていた。\n",
       "4  彼は貧しかったので、大学へ行けなかった。  彼はお金がなかったので、大学へ行くことができなかった。"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X150.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c62cd00-9fda-40f2-a4e8-41840d2eb6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2Vec object from word2vec.gensim.model\n",
      "INFO:gensim.utils:loading wv recursively from word2vec.gensim.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from word2vec.gensim.model.wv.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from word2vec.gensim.model.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:Word2Vec lifecycle event {'fname': 'word2vec.gensim.model', 'datetime': '2023-02-18T17:47:59.747479', 'gensim': '4.3.0', 'python': '3.8.12 (default, Sep 24 2022, 11:39:20) \\n[GCC 9.4.0]', 'platform': 'Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "term_list = get_simplified_terms(X150, 2000)\n",
    "model = Word2Vec.load(\"word2vec.gensim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "052e423d-6565-472b-abf1-6c49c9e0465e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data file type OK\n",
      "WARNING:root:\"Key '今本' not present in vocabulary\". Term will not be replaced.\n",
      "WARNING:root:\"Key '月ぎめ' not present in vocabulary\". Term will not be replaced.\n",
      "WARNING:root:\"Key '起ころう' not present in vocabulary\". Term will not be replaced.\n",
      "WARNING:root:\"Key 'おわらし' not present in vocabulary\". Term will not be replaced.\n",
      "WARNING:root:\"Key '金離れ' not present in vocabulary\". Term will not be replaced.\n",
      "INFO:root:9.060764789581299\n"
     ]
    }
   ],
   "source": [
    "predictions = replace_terms(X150['original'], term_list=term_list, wv=model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cee45dff-f5a8-4e6e-862c-a285e6b17324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     月曜時刻までにこの仕事を終えるてください。\n",
       "1           失敗図っても諦めては構わない。\n",
       "2       あなたは幾を思い浮かべておりのですか。\n",
       "3             その男の子は母と似てきた。\n",
       "4    彼自身は貧しかったので、大学へ歩けなかった。\n",
       "5           彼女自身はとても運転がざらだ。\n",
       "6           どんな寝室でもないよりはよい。\n",
       "7      クラスメートがそんな事を言った筈がない。\n",
       "8        あたしが成功図ったと聞いてうれしい。\n",
       "9            貴方の父はクラスメートです。\n",
       "Name: original, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "190ed434-17ae-473c-9525-fcf6c53b36ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>彼女自身は諺をいくつも知っており。</td>\n",
       "      <td>彼女は昔から知られてい短い言葉をいくつも知っている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>貴方たちのチームが勝つ事を断言図ってきます。</td>\n",
       "      <td>私たちのチームが勝つと思っている。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>貴方は日本の前史に関心があり。</td>\n",
       "      <td>私は日本の歴史に興味がある。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>貴方は時折学校で彼女自身に会う。</td>\n",
       "      <td>私は時々学校で彼女に会う。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>客車は何処で乗らますか。</td>\n",
       "      <td>列車はどこで乗ることができますか。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    predict                  simplified\n",
       "145       彼女自身は諺をいくつも知っており。  彼女は昔から知られてい短い言葉をいくつも知っている。\n",
       "146  貴方たちのチームが勝つ事を断言図ってきます。           私たちのチームが勝つと思っている。\n",
       "147         貴方は日本の前史に関心があり。              私は日本の歴史に興味がある。\n",
       "148        貴方は時折学校で彼女自身に会う。               私は時々学校で彼女に会う。\n",
       "149            客車は何処で乗らますか。           列車はどこで乗ることができますか。"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'predict': predictions, 'simplified': X150['simplified'].to_list()}\n",
    "pred_df = pd.DataFrame(data=d)\n",
    "pred_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ded47b6d-f527-40b2-9a6e-0f288cff76d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         月曜日までにこの仕事を終えて下さい。\n",
       "1           失敗してもあきらめてはいけない。\n",
       "2          あなたは何を見つめているのですか。\n",
       "3              その女の子は母と似ていた。\n",
       "4       彼は貧しかったので、大学へ行けなかった。\n",
       "               ...          \n",
       "145       彼女はことわざをいくつも知っている。\n",
       "146    私たちのチームが勝つことを確信しています。\n",
       "147           私は日本の歴史に興味がある。\n",
       "148            私は時折学校で彼女に会う。\n",
       "149             電車はどこで乗れますか。\n",
       "Name: original, Length: 150, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X150['original']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32725547-8e1c-420d-912d-c3ed6d2832ea",
   "metadata": {},
   "source": [
    "# 3. Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84ff93-4aaa-4e8a-942f-0561e074125b",
   "metadata": {},
   "source": [
    "### 3.1) WER SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dc16002-d961-47ba-9d07-645fc49f6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer_score(predicted, simplified, debug=True):\n",
    "    '''\n",
    "    Compares the simplified ML prediction of a given text to the pre-existing simplified\n",
    "    text given with the dataframe.\n",
    "    Using the WER (word error rate) algorithm.\n",
    "    Adds the WER score as a new column to the Dataframe\n",
    "    '''\n",
    "    r = predicted.split()\n",
    "    h = simplified.split()\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\n",
    "    OP_OK = 0\n",
    "    OP_SUB = 1\n",
    "    OP_INS = 2\n",
    "    OP_DEL = 3\n",
    "    DEL_PENALTY = 1\n",
    "    INS_PENALTY = 1\n",
    "    SUB_PENALTY = 1\n",
    "    for i in range(1, len(r)+1):\n",
    "        costs[i][0] = DEL_PENALTY*i\n",
    "        backtrace[i][0] = OP_DEL\n",
    "    for j in range(1, len(h) + 1):\n",
    "        costs[0][j] = INS_PENALTY * j\n",
    "        backtrace[0][j] = OP_INS\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                costs[i][j] = costs[i-1][j-1]\n",
    "                backtrace[i][j] = OP_OK\n",
    "            else:\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                if costs[i][j] == substitutionCost:\n",
    "                    backtrace[i][j] = OP_SUB\n",
    "                elif costs[i][j] == insertionCost:\n",
    "                    backtrace[i][j] = OP_INS\n",
    "                else:\n",
    "                    backtrace[i][j] = OP_DEL\n",
    "    # back trace though the best route:\n",
    "    i = len(r)\n",
    "    j = len(h)\n",
    "    numSub = 0\n",
    "    numDel = 0\n",
    "    numIns = 0\n",
    "    numCor = 0\n",
    "    if debug:\n",
    "        lines = []\n",
    "    while i > 0 or j > 0:\n",
    "        if backtrace[i][j] == OP_OK:\n",
    "            numCor += 1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_SUB:\n",
    "            numSub +=1\n",
    "            i-=1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\n",
    "        elif backtrace[i][j] == OP_INS:\n",
    "            numIns += 1\n",
    "            j-=1\n",
    "            if debug:\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "        elif backtrace[i][j] == OP_DEL:\n",
    "            numDel += 1\n",
    "            i-=1\n",
    "            if debug:\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\n",
    "    return (numSub + numDel + numIns) / (float) (len(r))\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\n",
    "    \n",
    "    \n",
    "def wer_jp(original, simplified):\n",
    "    ori = ''\n",
    "    simpi = ''\n",
    "    for i in original:\n",
    "        ori += i + ' '\n",
    "    for i in simplified:\n",
    "        simpi += i + ' '\n",
    "    return round(wer_score(ori, simpi),3)\n",
    "\n",
    "\n",
    "def evaluate_wer_score(df):\n",
    "    wer_list = []\n",
    "    for i in df.index:\n",
    "        original_text = df.iloc[i][0]\n",
    "        simplified_text = df.iloc[i][1]\n",
    "        wer_list.append(wer_jp(original_text, simplified_text))\n",
    "    df['WER_score'] = wer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28e983-c284-4cfa-9d0d-7191de5a008f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b9cf900-f3fd-4f31-a515-811a622cbec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>simplified</th>\n",
       "      <th>WER_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>月曜時刻までにこの仕事を終えるてください。</td>\n",
       "      <td>月曜日までにこの仕事を終わらせてください。</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>失敗図っても諦めては構わない。</td>\n",
       "      <td>失敗してもダメと思ってはならない。</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>あなたは幾を思い浮かべておりのですか。</td>\n",
       "      <td>あなたは何を見ているのですか。</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>その男の子は母と似てきた。</td>\n",
       "      <td>その少女は母と似ていた。</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>彼自身は貧しかったので、大学へ歩けなかった。</td>\n",
       "      <td>彼はお金がなかったので、大学へ行くことができなかった。</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>彼女自身はとても運転がざらだ。</td>\n",
       "      <td>彼女はとても運転がうまくない。</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>どんな寝室でもないよりはよい。</td>\n",
       "      <td>どんなベッドでもないよりはよい。</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>クラスメートがそんな事を言った筈がない。</td>\n",
       "      <td>先生がそんなことを言ったはずがない。</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>あたしが成功図ったと聞いてうれしい。</td>\n",
       "      <td>あなたが成功したと聞いて嬉しい。</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>貴方の父はクラスメートです。</td>\n",
       "      <td>私の父は先生です。</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>彼自身は東京ディジョンに住んでおり。</td>\n",
       "      <td>彼は東京に近いところに住んでいる。</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>貴方は今本を読んできます。</td>\n",
       "      <td>私は今、本を読んでいます。</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>尋ねる直前によく考えていらねば及ばない。</td>\n",
       "      <td>答える前によく考えてもらわねばならない。</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>彼自身は貴方を許してもらうだろう。</td>\n",
       "      <td>彼は私を許してくれるだろう。</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>彼自身はオランダアラビア語を勉学言い出すと図った。</td>\n",
       "      <td>彼はフランス語を勉強しようとした。</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>率直な意見を聞きたい。</td>\n",
       "      <td>心からの意見を聞きたい。</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>あたしは泳ぐんだろう?</td>\n",
       "      <td>あなたは泳ぐことができるんだろう？</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>彼自身が本当の理由を見つけようと図ったって無理だ。</td>\n",
       "      <td>彼が本当の理由を見つけようとしても意味がない。</td>\n",
       "      <td>0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>入場券なしで客車に乗っては歩けません。</td>\n",
       "      <td>チケットなしで列車に乗ってはなりません。</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>貴方たちのクラスメートは時々話せるのが速い。</td>\n",
       "      <td>私たちの先生は時々話すのが速い。</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>彼自身は駅で一時間やらされた。</td>\n",
       "      <td>彼は駅で２時間待った。</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>この道路は、車は駐車緩めになりており。</td>\n",
       "      <td>この道路は、車は通ることが出来なくなっている。</td>\n",
       "      <td>0.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>貴方は彼自身の不法行為を許した。</td>\n",
       "      <td>私は彼の間違いを許した。</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>貴方は月ぎめで部屋を借りており。</td>\n",
       "      <td>私は月単位で部屋を借りている。</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>今、忙しいの。</td>\n",
       "      <td>今、忙しいの。</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>彼自身は貴方にさよならさえ言わなかった。</td>\n",
       "      <td>彼は私にさようならさえ言わなかった。</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>お前さんはお元気?</td>\n",
       "      <td>みんなはお元気？</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>彼自身は新しい研究に汝を忘れた。</td>\n",
       "      <td>彼は新しい研究に自分を忘れた。</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>今夜昼休みを踏み込むと思っており。</td>\n",
       "      <td>明日休みをとろうと思っている。</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>行くか会わないかは天気必ずです。</td>\n",
       "      <td>行くか行かないかは天気次第です。</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>率直に言って貴方はあなたと行きたくない。</td>\n",
       "      <td>隠さずに言って私はあなたと行きたくない。</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>貴方たちは時々釣りに行く。</td>\n",
       "      <td>私たちは時々魚を釣りに行く。</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>猫は覗いてきます。</td>\n",
       "      <td>赤ちゃんは寝ています。</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>彼自身らは資金提供を必要と図っており。</td>\n",
       "      <td>彼らは協力を必要としている。</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>彼自身は一度とこれを言わなかった。</td>\n",
       "      <td>彼は２度とそれを言わなかった。</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>幾が起きたの。</td>\n",
       "      <td>何が起こったの。</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>今日から島丸1日お願い図っます。</td>\n",
       "      <td>今日から１日の全てお願いします。</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>仕事の図っすぎで彼自身は体を壊した。</td>\n",
       "      <td>仕事のばかりに集中していて彼は体を壊した。</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>商社の成功は彼自身のお陰だ。</td>\n",
       "      <td>会社の成功は彼のおかげだ。</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>貴方はやっと宿題を張り替えた。</td>\n",
       "      <td>私はやっと宿題が終わった。</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      predict                   simplified  WER_score\n",
       "0       月曜時刻までにこの仕事を終えるてください。        月曜日までにこの仕事を終わらせてください。      0.238\n",
       "1             失敗図っても諦めては構わない。            失敗してもダメと思ってはならない。      0.600\n",
       "2         あなたは幾を思い浮かべておりのですか。              あなたは何を見ているのですか。      0.421\n",
       "3               その男の子は母と似てきた。                 その少女は母と似ていた。      0.308\n",
       "4      彼自身は貧しかったので、大学へ歩けなかった。  彼はお金がなかったので、大学へ行くことができなかった。      0.545\n",
       "5             彼女自身はとても運転がざらだ。              彼女はとても運転がうまくない。      0.467\n",
       "6             どんな寝室でもないよりはよい。             どんなベッドでもないよりはよい。      0.200\n",
       "7        クラスメートがそんな事を言った筈がない。           先生がそんなことを言ったはずがない。      0.500\n",
       "8          あたしが成功図ったと聞いてうれしい。             あなたが成功したと聞いて嬉しい。      0.333\n",
       "9              貴方の父はクラスメートです。                    私の父は先生です。      0.571\n",
       "10         彼自身は東京ディジョンに住んでおり。            彼は東京に近いところに住んでいる。      0.556\n",
       "11              貴方は今本を読んできます。                私は今、本を読んでいます。      0.308\n",
       "12       尋ねる直前によく考えていらねば及ばない。         答える前によく考えてもらわねばならない。      0.350\n",
       "13          彼自身は貴方を許してもらうだろう。               彼は私を許してくれるだろう。      0.412\n",
       "14  彼自身はオランダアラビア語を勉学言い出すと図った。            彼はフランス語を勉強しようとした。      0.600\n",
       "15                率直な意見を聞きたい。                 心からの意見を聞きたい。      0.364\n",
       "16                あたしは泳ぐんだろう?            あなたは泳ぐことができるんだろう？      0.818\n",
       "17  彼自身が本当の理由を見つけようと図ったって無理だ。      彼が本当の理由を見つけようとしても意味がない。      0.400\n",
       "18        入場券なしで客車に乗っては歩けません。         チケットなしで列車に乗ってはなりません。      0.368\n",
       "19     貴方たちのクラスメートは時々話せるのが速い。             私たちの先生は時々話すのが速い。      0.455\n",
       "20            彼自身は駅で一時間やらされた。                  彼は駅で２時間待った。      0.467\n",
       "21        この道路は、車は駐車緩めになりており。      この道路は、車は通ることが出来なくなっている。      0.632\n",
       "22           貴方は彼自身の不法行為を許した。                 私は彼の間違いを許した。      0.500\n",
       "23           貴方は月ぎめで部屋を借りており。              私は月単位で部屋を借りている。      0.375\n",
       "24                    今、忙しいの。                      今、忙しいの。      0.000\n",
       "25       彼自身は貴方にさよならさえ言わなかった。           彼は私にさようならさえ言わなかった。      0.250\n",
       "26                  お前さんはお元気?                     みんなはお元気？      0.556\n",
       "27           彼自身は新しい研究に汝を忘れた。              彼は新しい研究に自分を忘れた。      0.250\n",
       "28          今夜昼休みを踏み込むと思っており。              明日休みをとろうと思っている。      0.529\n",
       "29           行くか会わないかは天気必ずです。             行くか行かないかは天気次第です。      0.250\n",
       "30       率直に言って貴方はあなたと行きたくない。         隠さずに言って私はあなたと行きたくない。      0.250\n",
       "31              貴方たちは時々釣りに行く。               私たちは時々魚を釣りに行く。      0.308\n",
       "32                  猫は覗いてきます。                  赤ちゃんは寝ています。      0.778\n",
       "33        彼自身らは資金提供を必要と図っており。               彼らは協力を必要としている。      0.526\n",
       "34          彼自身は一度とこれを言わなかった。              彼は２度とそれを言わなかった。      0.235\n",
       "35                    幾が起きたの。                     何が起こったの。      0.429\n",
       "36           今日から島丸1日お願い図っます。             今日から１日の全てお願いします。      0.438\n",
       "37         仕事の図っすぎで彼自身は体を壊した。        仕事のばかりに集中していて彼は体を壊した。      0.611\n",
       "38             商社の成功は彼自身のお陰だ。                会社の成功は彼のおかげだ。      0.357\n",
       "39            貴方はやっと宿題を張り替えた。                私はやっと宿題が終わった。      0.467"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_wer_score(pred_df)\n",
    "pred_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bca9c8-37e0-4724-84c4-aeb37b860796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2801c64-40da-499f-b6f1-73fc0a41fb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4377999999999999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['WER_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36cc6ba7-522a-4a4d-8457-da13504ae491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2200533333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_wer_score(X150)\n",
    "X150['WER_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afac5f6-e2e6-4e43-a684-e2b5ebe4e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG:root:Currrent sentence: 彼は部屋をきちんと整理した。\n",
    "DEBUG:root:['彼自身', 'は', '部屋', 'を', 'きちんと', '整理', '図っ', 'た', '。']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f291a-69ca-4a79-99b2-03e18f7ded63",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de6fd1b-fb33-408a-969b-ec5fff3d87c5",
   "metadata": {},
   "source": [
    "# 3.1) Data Organization and Clean Up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b8eacf-b13a-4b4f-8a89-ac83ce9db324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the imported libraries go here for Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15aed2-a563-4d94-89b3-97a81772597c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb2145ed41b1af7fe232120fa962063b18150619d590444428e8892237256527"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
